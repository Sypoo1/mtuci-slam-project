import cv2
import numpy as np
from skimage.measure import ransac
from skimage.transform import FundamentalMatrixTransform


def add_ones(x):
    # concatenates the original array x with the column of ones along the second axis (columns).
    # This converts the N√ó2 array to an N√ó3 array where each point is represented
    # in homogeneous coordinates as [x,y,1].
    return np.concatenate([x, np.ones((x.shape[0], 1))], axis=1)


IRt = np.eye(4)


def extractPose(F):
    # W = np.mat([[0,-1,0],[1,0,0],[0,0,1]])
    W = np.asmatrix([[0, -1, 0], [1, 0, 0], [0, 0, 1]])

    U, d, Vt = np.linalg.svd(F)
    assert np.linalg.det(U) > 0 # –µ—Å–ª–∏ < 0 –∫–∞–¥—Ä/–ø–∞—Ä–∞ –∫–∞–¥—Ä‚Äì–∫–∞–¥—Ä –∏–º–µ–µ—Ç –∫—Ä–∞–π–Ω–µ –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤—ã–ª–µ—Ç —á–µ—Ä–µ–∑ —á–∏—Å–ª–µ–Ω–Ω—É—é –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
    if np.linalg.det(Vt) < 0:
        Vt *= -1
    R = np.dot(np.dot(U, W), Vt)
    if np.sum(R.diagonal()) < 0:
        R = np.dot(np.dot(U, W.T), Vt)
    t = U[:, 2]
    ret = np.eye(4)
    ret[:3, :3] = R
    ret[:3, 3] = t
    # print(d)
    return ret


def extract(img):
    orb = cv2.ORB_create()

    # Convert to grayscale
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detection
    pts = cv2.goodFeaturesToTrack(gray_img, 8000, qualityLevel=0.01, minDistance=10)

    if pts is None:
        return np.array([]), None

    # Extraction
    kps = [cv2.KeyPoint(f[0][0], f[0][1], 20) for f in pts]
    kps, des = orb.compute(gray_img, kps)

    return np.array([(kp.pt[0], kp.pt[1]) for kp in kps]), des


def normalize(Kinv, pts):
    # The inverse camera intrinsic matrix ùêæ ‚àí 1 transforms 2D homogeneous points
    # from pixel coordinates to normalized image coordinates. This transformation centers
    # the points based on the principal point (ùëêùë• , ùëêùë¶) and scales them
    # according to the focal lengths ùëìùë• and ùëìùë¶, effectively mapping the points
    # to a normalized coordinate system where the principal point becomes the origin and
    # the distances are scaled by the focal lengths.
    return np.dot(Kinv, add_ones(pts).T).T[:, 0:2]
    # `[:, 0:2]` selects the first two columns of the resulting array, which are the normalized x and y coordinates.
    # `.T` transposes the result back to N x 3.


def denormalize(K, pt):
    ret = np.dot(K, [pt[0], pt[1], 1.0])
    ret /= ret[2]
    return int(round(ret[0])), int(round(ret[1]))


class Matcher(object):
    def __init__(self):
        self.last = None

def match_frames(f1, f2):
    """
    –ù–∞ –≤—Ö–æ–¥: –¥–≤–∞ –æ–±—ä–µ–∫—Ç–∞ Frame —Å –ø–æ–ª—è–º–∏:
      - f1.des, f2.des ‚Äî –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (N√ó32)
      - f1.pts, f2.pts ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ (N√ó2)
    –ù–∞ –≤—ã—Ö–æ–¥: idx1, idx2 ‚Äî –∏–Ω–¥–µ–∫—Å—ã inliers –≤ f1.pts –∏ f2.pts, –∏ 4√ó4 Rt-–º–∞—Ç—Ä–∏—Ü–∞.
    –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π < 8 –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ inliers, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (None, None, None).
    """

    # 1) BFMatcher + Lowe‚Äôs ratio test
    bf = cv2.BFMatcher(cv2.NORM_HAMMING)
    matches = bf.knnMatch(f1.des, f2.des, k=2)
    idx1, idx2 = [], []
    for m, n in matches:
        # Lowe‚Äôs ratio: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã :contentReference[oaicite:2]{index=2}
        if m.distance < 0.75 * n.distance:
            p1 = f1.pts[m.queryIdx]
            p2 = f2.pts[m.trainIdx]
            # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å–º–µ—â–µ–Ω–∏—é
            if np.linalg.norm(p1 - p2) < 0.1:
                idx1.append(m.queryIdx)
                idx2.append(m.trainIdx)

    idx1 = np.array(idx1, dtype=int)
    idx2 = np.array(idx2, dtype=int)

    # 2) –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–æ—á–µ–∫ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä
    if len(idx1) < 8:
        return None, None, None

    # 3) –°–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞—Å—Å–∏–≤—ã –¥–ª—è findFundamentalMat
    pts1 = f1.pts[idx1]
    pts2 = f2.pts[idx2]

    # 4) –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É RANSAC º–æ–º
    F, mask = cv2.findFundamentalMat(
        pts1, pts2,
        method=cv2.FM_RANSAC,
        ransacReprojThreshold=0.005,
        confidence=0.99,
        maxIters=200
    )  # :contentReference[oaicite:3]{index=3}

    if F is None or mask is None:
        return None, None, None

    # 5) –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ç–∏–Ω–Ω—ã–µ inliers
    mask = mask.ravel().astype(bool)
    idx1_in = idx1[mask]
    idx2_in = idx2[mask]

    if len(idx1_in) < 8:
        # –¥–∞–∂–µ –ø–æ—Å–ª–µ RANSAC –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–æ—á–µ–∫
        return None, None, None

    # 6) –ò–∑–≤–ª–µ–∫–∞–µ–º 4√ó4 Rt-–º–∞—Ç—Ä–∏—Ü—É –∏–∑ F
    Rt = extractPose(F)

    return idx1_in, idx2_in, Rt

def match_frames_old(f1, f2):
    bf = cv2.BFMatcher(cv2.NORM_HAMMING)
    matches = bf.knnMatch(f1.des, f2.des, k=2)

    # Lowe's ratio test
    ret = []
    idx1, idx2 = [], []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            p1 = f1.pts[m.queryIdx]
            p2 = f2.pts[m.trainIdx]

            # Distance test
            # dditional distance test, ensuring that the
            # Euclidean distance between p1 and p2 is less than 0.1
            if np.linalg.norm((p1 - p2)) < 0.1:
                # Keep idxs
                idx1.append(m.queryIdx)
                idx2.append(m.trainIdx)
                ret.append((p1, p2))
                pass

    # # –ï—Å–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–µ–Ω—å—à–µ 8, –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ –º–æ–∂–µ—Ç –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
    # assert len(ret) >= 8

    if len(ret) < 8:
        # –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –∫–∞–¥—Ä
        return None, None, None

    ret = np.array(ret)
    idx1 = np.array(idx1)
    idx2 = np.array(idx2)

    # Fit matrix
    model, inliers = ransac(
        (ret[:, 0], ret[:, 1]),
        FundamentalMatrixTransform,
        min_samples=8,
        residual_threshold=0.005,
        max_trials=200,
    )

    # Ignore outliers
    ret = ret[inliers]
    Rt = extractPose(model.params)

    return idx1[inliers], idx2[inliers], Rt


class Frame(object):
    def __init__(self, mapp, img, K):
        self.K = K
        self.Kinv = np.linalg.inv(self.K)
        self.pose = IRt

        self.id = len(mapp.frames)
        mapp.frames.append(self)

        pts, self.des = extract(img)

        if self.des.any() != None:
            self.pts = normalize(self.Kinv, pts)
